# deep learning  Chapter 08
## Optimization for Training Deep Models

---
## disclaimer
- 本文を大胆に要約して整理した
    - 議論のたたき台にしてほしい
    - みんな読んでるよね！！！
- 大事なところが足りないと思ったらコメントしてほしい

---
## Lead
- NN における最適化に焦点を当てて説明を行う
    - 一般的な最適化の話に不安がある場合は 4章を振り返ること

---
## 8.1 How Learning Differs from Pure Optimization
- NNの学習に用いられる最適化手法は一般的な最適化手法とは異なる点が多い
- 以下のような点が挙げられる
    - 代理損失関数の最小化により間接的に性能指標Pを改善する
    - 勾配が0になる前に終了する
    - ミニバッチ法を用いる

+++
### 8.1.1 Empirical Risk Minimization
- 経験分布に基づく経験損失最小化では NN の学習は困難である
    1. モデルパラメータが多く訓練集合を記憶できてしまう
    1. 損失関数の勾配を求めることが難しい場合が多い

+++
### 8.1.2 Surrogate Loss Functions and Early Stopping
- 本来の損失関数ではなく扱いやすい代理損失関数の最小化を行う
    - ex. 不連続関数を連続関数にする など
    - 代理関数を使うことでより学習の効果を高められる場合もある
- NN の学習は極小値(最小値含む)にたどり着く前に終了することがほとんどである
    - 事前に定めた早期終了条件で停止する
    - overfit を避けるため

+++
### 8.1.3 Batch and Minibatch Algorithms
- 学習には一般的にミニバッチ法を用いる
    - 勾配推定精度の低減
    - ハードウェア制約 など
- ミニバッチはランダムサンプリングにより構成される

---
## 8.2 Challenges in Neural Network Optimization
- ニューラルネットワークの最適化における有名な課題を列挙する
- どの課題がニューラルネットワークの最適化における本質的な難しさであるかはまだわかっていない

+++
### 8.2.1 Ill-Conditioning
- 凸最適化において、ヘッセ行列の悪条件であることが課題となることが知られている
- NN においても同様のことが言える
- 凸最適化では悪条件の場合にニュートン法が利用される
- しかしニューラルネットワークに適用するにはアルゴリズムに大きな変更が必要である

+++
### 8.2.2 Local Minima
- 目的関数が非凸であるため、極小値に落ちることがある
- 実務家(研究者ではなくNNで実問題を解くものを指していると思われる)は最適化の難しさを極小値によるものと考える傾向にある
- 最近の研究では、十分大きなNNでは極小値のコストは小さくなることが多いことがわかってきた

+++
### 8.2.3 Plateaus, Saddle Points and Other Flat Regions
- 高次の非凸関数では鞍点は極小値に比べて多くなる
- ただし経験的に勾配法は鞍点を避けることが知られている
- 一方、平坦な領域は任意の最適化手法で問題が生じる
    - 凸最適化の場合、平坦な領域は最適値となるため問題にならなかった

+++
### 8.2.4 Cliffs and Exploding Gradients
- 目的関数の勾配が急なところでパラメータが大きくジャンプしてしまう
- 勾配クリッピングにより回避可能
    - 更新量の上限を決めて勾配方向に更新するイメージ
- RNN で生じやすい
    - 同じ因子を繰り返し掛け算することによるとのこと
    - おそらく 8.11 式
+++
### 8.2.5 Long-Term Dependencies
- 同じパラメータを繰り返し利用する場合に発生する
    - ex. RNN
- 勾配爆発 or 勾配消失を引き起こす
    - 理由は 8.11 式を見ればわかる
- FFNN では層毎の重みが異なるため起こらない

+++
### 8.2.6 Inexact Gradients
- 必ずしも正確に勾配を求められるわけではない
    - 目的関数が複雑なため
    - サンプリングを行うため など
- NN のために設計された最適化手法は不正確な勾配でもうまく動くよう作られている

+++
### 8.2.7 Poor Correspondence between Local and Global Structure
- 勾配方向をたどっていっても必ずしもコストを十分下げられるわけではない
    - 極小値におちるという**意味ではない**
    - 極小値にすら(もちろん最小値にすら)たどり着かずに学習が終わることが多い
- うまい初期値を選択できれば回避できる
    - のでその研究が進められている
+++
### 8.2.8 Theoretical Limits of Optimization
- どの最適化手法に対しても NN の性能に理論限界があることが示されている
    - 実務的には大きな問題にはならない

---
## 8.3 Basic Algorithms
- stochastic gradient descent (SGD)について説明する
    - ミニバッチで勾配を推定する勾配降下法
+++
### 8.3.1 Stochastic Gradient Descent
- ミニバッチにて勾配を推定する最急降下法
    - 最小値で勾配が0にならない
    - 学習率を動的に変える必要あり = 設定が職人芸的
- 理論的にはバッチ勾配降下法の方がSGDより性能が良い
- 実務的には SGD を使うメリットは様々ある
    - 訓練データサイズとが増えても計算時間はそれほど変わらない
    - 訓練データサイズ大きくても収束する など

+++
### 8.3.2 Momentum
- 過去の勾配の蓄積と現在の勾配を混ぜて更新量を決定
    - 8.15-8.16式
    - 勾配方向にある程度一貫性を持たせることで、悪条件のヘッセ行列による影響を軽減
- 物理学的な解釈もできなくはない
    - こういうのは人によって好き嫌いがあるように思う

+++
### 8.3.3 Nesterov Momentum
- momentum SGD の勾配の計算位置を変更
    - 8.22 式
- 凸関数に対するバッチ勾配法(アイデアの着想元となった手法)の場合、収束率が改善する
    - ミニバッチを利用する場合、収束率は改善しない

---
## 8.4 Parameter Initialization Strategies
- NN の学習手法は初期値依存性が高く、解への収束は保証されていない
- 一方初期点の選択方法についてはまだまだわかっていないことが多い
- 現在わかっていることや提案されている初期化戦略を紹介する

+++
- 同じ入力・同じ活性化関数を持つ異なるユニット同士は異なる初期パラメータをもたせる
    - 決定論的な手法の場合同じ値に更新され続けるため
    - 確率的な手法の場合でもこのようにするのが一般的
- パラメータが相互に異なるように決定する方法は存在する
    - ただし初期化に無視できないコストがかかってしまう
    - 例えばグラム・シュミットの直行化法を用いればよい

+++
- バイアスはヒューリスティックに基づき選択し、重みだけランダムに初期化するのが一般的

+++
- 最適化と正則化では初期化に対して異なる洞察を与える
- 最適化
    - 初期重みは大きくする
    - 対称性を破る効果が高まる
- 正則化
    - 初期重みは小さくする
    - 学習が安定する

+++
- 初期パラメータは事前分布を与えることに相当する
- 初期パラメータが0に近い
    - ユニット間の相互作用がない可能性が高い
- 入力 m, 出力 n の全結合層の場合、以下のような初期値の選択方法が提案されている
    - $$U(-frac{1}{sqrt(m)},frac{1}{sqrt(m)})$$
    - $$U(-sqrt(frac{6}{m+n}),sqrt(frac{6}{m+n})$$

+++
- スパース初期化(非ゼロの重みが k 個になるような初期化)も提案されている
    - $$frac{1}{sqrt(m)}$$ は m が大きくなると非常に小さくなるので全てのユニットで重みが小さくなってしまうことへの対策
    - 非ゼロ要素に対して強い相関を仮定した事前分布となっている

+++
- 重みパラメータ以外のパラメータは重みに比べ初期化は簡単である
